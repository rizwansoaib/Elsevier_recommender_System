{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from elsapy.elsclient import ElsClient\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "con_file = open(\"config.json\")\n",
    "config = json.load(con_file)\n",
    "con_file.close()\n",
    "\n",
    "\n",
    "client = ElsClient(config['apikey'])\n",
    "client.inst_token = config['insttoken']\n",
    "\n",
    "pii_doc = FullDoc(sd_pii = 'S0950705118302107')\n",
    "if pii_doc.read(client):\n",
    "    print()\n",
    "else:\n",
    "    print (\"Read document failed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Content=pii_doc.data['originalText']\n",
    "Abstract=pii_doc.data['coredata']['dc:description']\n",
    "Title=pii_doc.title\n",
    "Url=pii_doc.uri\n",
    "Date=pii_doc.data['coredata']['prism:coverDate']\n",
    "Creator=[pii_doc.data['coredata']['dc:creator'][name]['$'] for name in range(len(pii_doc.data['coredata']['dc:creator']))]\n",
    "Links=[pii_doc.data['coredata']['link'][index]['@href']  for index in range(len(pii_doc.data['coredata']['link'])) ]\n",
    "Term=[pii_doc.data['coredata']['dcterms:subject'][index]['$']    for index in range(len(pii_doc.data['coredata']['dcterms:subject']))    ]\n",
    "Pages=pii_doc.data['coredata']['prism:endingPage']\n",
    "Identifier=pii_doc.data['coredata']['dc:identifier']\n",
    "Publication_name=pii_doc.data['coredata']['prism:publicationName']\n",
    "\n",
    "\n",
    "StringCreator=\"\".join(Creator)\n",
    "\n",
    "StringTerm=\"\"\n",
    "for x in Term:\n",
    "    StringTerm+=x+\" \"+\",\"+\" \"\n",
    "    \n",
    "\n",
    "StringLinks=\"\"\n",
    "for x in Links:\n",
    "    StringLinks+=x+\" \"+\",\"+\" \"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "a = pd.Series(data=[Title])\n",
    "b = pd.Series(data=[Publication_name])\n",
    "c = pd.Series(data=[StringTerm])\n",
    "d = pd.Series(data=[StringCreator])\n",
    "e = pd.Series(data=[Date])\n",
    "f = pd.Series(data=[StringLinks])\n",
    "g = pd.Series(data=[Pages])\n",
    "h = pd.Series(data=[Identifier])\n",
    "i = pd.Series(data=[Abstract])\n",
    "j = pd.Series(data=[Content])\n",
    "a.name = 'Title'\n",
    "b.name= 'Publication_name'\n",
    "c.name = 'Term'\n",
    "d.name= 'Creator'\n",
    "e.name = 'Date'\n",
    "f.name= 'Links'\n",
    "g.name = 'Pages'\n",
    "h.name= 'Identifier'\n",
    "i.name = 'Abstract'\n",
    "j.name= 'Content'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "frame = { a.name:a, b.name:b,c.name:c, d.name:d,e.name:e, f.name:f,g.name:g, h.name:h,i.name:i, j.name:j } \n",
    "\n",
    "df=pd.DataFrame(frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_abs(df):\n",
    "    for x in df['Abstract']:\n",
    "        print(x)\n",
    "\n",
    "def show_title(df):\n",
    "    for x in df['Title']:\n",
    "        print(x)\n",
    "        \n",
    "def show_pub(df):\n",
    "    for x in df['Publication_name']:\n",
    "        print(x)\n",
    "        \n",
    "        \n",
    "def show_term(df):\n",
    "    for x in df['Term']:\n",
    "        print(x)\n",
    "        \n",
    "def show_creator(df):\n",
    "    for x in df['Creator']:\n",
    "        print(x)\n",
    "\n",
    "def show_date(df):\n",
    "    for x in df['Date']:\n",
    "        print(x)\n",
    "        \n",
    "def show_link(df):\n",
    "    for x in df['Links']:\n",
    "        print(x)\n",
    "        \n",
    "        \n",
    "def show_content(df):\n",
    "    for x in df['Content']:\n",
    "        print(x)\n",
    "        \n",
    "def show_page(df):\n",
    "    for x in df['Pages']:\n",
    "        print(x)\n",
    "        \n",
    "        \n",
    "def show_dio(df):\n",
    "    for x in df['Identifier']:\n",
    "        print(x)\n",
    "        \n",
    "        \n",
    "def show_all(df):\n",
    "    print(\"Publication_Name: \",end=\"\")\n",
    "    show_pub(df)\n",
    "    print(\"\\n\\n\\n\\nTerm: \",end=\"\")\n",
    "    show_term(df)\n",
    "    print(\"\\n\\n\\n\\nCreator_Name: \",end=\"\")\n",
    "    show_creator(df)\n",
    "    print(\"\\n\\n\\n\\nPublication_Date: \",end=\"\")\n",
    "    show_date(df)\n",
    "    print(\"\\n\\n\\n\\nPublication_Link: \",end=\"\")\n",
    "    show_link(df)\n",
    "    print(\"\\n\\n\\n\\nPublication_Pages: \",end=\"\")\n",
    "    show_page(df)\n",
    "    print(\"\\n\\n\\n\\nPublication_dio: \",end=\"\")\n",
    "    show_dio(df)\n",
    "    print(\"\\n\\n\\n\\nPublication_Abstract: \",end=\"\")\n",
    "    show_abs(df)\n",
    "    print(\"\\n\\n\\n\\nPublication_Content: \",end=\"\")\n",
    "    show_content(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication_name</th>\n",
       "      <th>Term</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Date</th>\n",
       "      <th>Links</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A content-based recommender system for compute...</td>\n",
       "      <td>Knowledge-Based Systems</td>\n",
       "      <td>Recommender system , Softmax regression , Chi-...</td>\n",
       "      <td>Wang, DonghuiLiang, YanchunXu, DongFeng, Xiaoy...</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>9</td>\n",
       "      <td>doi:10.1016/j.knosys.2018.05.001</td>\n",
       "      <td>Abstract As computer science and information t...</td>\n",
       "      <td>serial JL 271505 291210 291818 291866 291883 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title         Publication_name                                               Term                                            Creator        Date                                              Links Pages                        Identifier                                           Abstract                                            Content\n",
       "0  A content-based recommender system for compute...  Knowledge-Based Systems  Recommender system , Softmax regression , Chi-...  Wang, DonghuiLiang, YanchunXu, DongFeng, Xiaoy...  2018-10-01  https://api.elsevier.com/content/article/pii/S...     9  doi:10.1016/j.knosys.2018.05.001  Abstract As computer science and information t...  serial JL 271505 291210 291818 291866 291883 3..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A content-based recommender system for compute...\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://api.elsevier.com/content/article/pii/S...\n",
       "Name: Links, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Links\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Wang, DonghuiLiang, YanchunXu, DongFeng, Xiaoy...\n",
       "Name: Creator, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Creator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:1000000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:1000000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publication_Name: Knowledge-Based Systems\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Term: Recommender system , Softmax regression , Chi-square feature selection , Computer science publications , \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Creator_Name: Wang, DonghuiLiang, YanchunXu, DongFeng, XiaoyueGuan, Renchu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Publication_Date: 2018-10-01\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Publication_Link: https://api.elsevier.com/content/article/pii/S0950705118302107 , https://www.sciencedirect.com/science/article/pii/S0950705118302107 , \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Publication_Pages: 9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Publication_dio: doi:10.1016/j.knosys.2018.05.001\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Publication_Abstract: Abstract As computer science and information technology are making broad and deep impacts on our daily lives, more and more papers are being submitted to computer science journals and conferences. To help authors decide where they should submit their manuscripts, we present the Content-based Journals & Conferences Recommender System on computer science, as well as its web service at http://www.keaml.cn/prs/. This system recommends suitable journals or conferences with a priority order based on the abstract of a manuscript. To follow the fast development of computer science and technology, a web crawler is employed to continuously update the training set and the learning model. To achieve interactive online response, we propose an efficient hybrid model based on chi-square feature selection and softmax regression. Our test results show that, the system can achieve an accuracy of 61.37% and suggest the best journals or conferences in about 5 s on average.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Publication_Content: serial JL 271505 291210 291818 291866 291883 31 90 Knowledge-Based Systems KNOWLEDGEBASEDSYSTEMS 2018-05-17 2018-05-17 2018-06-17 2018-06-17 2018-06-28T15:08:37 1-s2.0-S0950705118302107 S0950-7051(18)30210-7 S0950705118302107 10.1016/j.knosys.2018.05.001 S300 S300.2 FULL-TEXT 1-s2.0-S0950705118X00173 2018-06-28T14:16:08.798318Z 0 0 20181001 2018 2018-05-17T03:16:20.805222Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table e-component body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid orcid primabst ref 0950-7051 09507051 UNLIMITED NONE true 157 157 C Volume 157 2 1 9 1 9 20181001 1 October 2018 2018-10-01 2018 article fla © 2018 The Authors. Published by Elsevier B.V. ACONTENTBASEDRECOMMENDERSYSTEMFORCOMPUTERSCIENCEPUBLICATIONS WANG D 1 Introduction 2 Background 3 Publication recommender system 3.1 Feature selection module 3.1.1 TF-IDF 3.1.2 Chi-square feature selection 3.1.3 Proposed method 3.2 Softmax regression module 3.2.1 Softmax regression 3.2.2 Proposed method 4 Experimental results and analysis 4.1 Dataset 4.2 Text preprocessing 4.3 Experiments and analysis 5 Conclusions Acknowledgments Appendix A Supplementary materials References CHEN 2015 830 839 M DIAO 2014 193 202 Q PROCEEDINGS20THACMSIGKDDINTERNATIONALCONFERENCEKNOWLEDGEDISCOVERYDATAMINING JOINTLYMODELINGASPECTSRATINGSSENTIMENTSFORMOVIERECOMMENDATIONJMARS QU 2013 776 787 W SCHEDL 2015 947 950 M PROCEEDINGS38THINTERNATIONALACMSIGIRCONFERENCERESEARCHDEVELOPMENTININFORMATIONRETRIEVAL TAILORINGMUSICRECOMMENDATIONSUSERSBYCONSIDERINGDIVERSITYMAINSTREAMINESSNOVELTY KAMINSKAS 2013 17 24 M PROCEEDINGS7THACMCONFERENCERECOMMENDERSYSTEMS LOCATIONAWAREMUSICRECOMMENDATIONUSINGAUTOTAGGINGHYBRIDMATCHING TURCOTTE 2015 520 535 J HOPFGARTNER 2014 250 267 F INTERNATIONALCONFERENCECROSSLANGUAGEEVALUATIONFORUMFOREUROPEANLANGUAGES BENCHMARKINGNEWSRECOMMENDATIONSINALIVINGLAB LU 2015 12 32 J ARMSTRONG 1995 6 12 R AAAISPRINGSYMPOSIUMINFORMATIONGATHERINGHETEROGENEOUSDISTRIBUTEDENVIRONMENTS WEBWATCHERALEARNINGAPPRENTICEFORWORLDWIDEWEB BALABANOVIC 1995 13 18 M ONLINEWORKINGNOTESAAAISPRINGSYMPOSIUMSERIESINFORMATIONGATHERINGDISTRIBUTEDHETEROGENEOUSENVIRONMENTS LEARNINGINFORMATIONRETRIEVALAGENTSEXPERIMENTSAUTOMATEDWEBBROWSING TERVEEN 1997 59 62 L KAUTZ 1997 63 65 H JOERDING 1999 99 107 T PROCEEDINGSSECONDWORKSHOPADAPTIVESYSTEMSUSERMODELINGWORLDWIDEWEBTORONTOBANFFCANADACOMPUTERSCIENCEREPORT ATEMPORARYUSERMODELINGAPPROACHFORADAPTIVESHOPPINGWEB MOORE 2001 1 B IBMREDBOOKS MIGRATINGWEBLOGICAPPLICATIONSWEBSPHEREADVANCEDEDITION JAFARKARIMI 2012 216 H MELVILLE 2011 829 838 P ENCYCLOPEDIAMACHINELEARNING RECOMMENDERSYSTEMS MOONEY 2000 195 204 R PROCEEDINGSFIFTHACMCONFERENCEDIGITALLIBRARIES CONTENTBASEDBOOKRECOMMENDINGUSINGLEARNINGFORTEXTCATEGORIZATION SHAMBOUR 2012 768 780 Q MAO 2017 4049 4061 M BOBADILLA 2013 109 132 J CHEN 2008 231 239 B GUPTA 2013 380 406 N COSTA 2015 39 60 R JIN 2015 351 362 C MOHDAMESLEH 2007 430 435 A OTAIR 2013 1 M PORTER 1980 130 137 M GIBAJA 2015 52 E WANGX2018X1 WANGX2018X1X9 WANGX2018X1XD WANGX2018X1X9XD Full 2018-05-16T22:50:14Z Author http://creativecommons.org/licenses/by-nc-nd/4.0/ 2020-06-17T00:00:00.000Z UnderEmbargo http://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license. © 2018 The Authors. Published by Elsevier B.V. item S0950-7051(18)30210-7 S0950705118302107 1-s2.0-S0950705118302107 10.1016/j.knosys.2018.05.001 271505 2018-06-28T14:16:08.798318Z 2018-10-01 UNLIMITED NONE 1-s2.0-S0950705118302107-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/MAIN/application/pdf/7ef1df34d36cc9421024169df6cc4d30/main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/MAIN/application/pdf/7ef1df34d36cc9421024169df6cc4d30/main.pdf main.pdf pdf true 2743057 MAIN 9 1-s2.0-S0950705118302107-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/PREVIEW/image/png/f4c4f0700f1795ce18c5799c722abecc/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/PREVIEW/image/png/f4c4f0700f1795ce18c5799c722abecc/main_1.png main_1.png png 56271 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0950705118302107-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr1/THUMBNAIL/image/gif/3739b9b6bfe5166c62fcf9e1cf467d89/gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr1/THUMBNAIL/image/gif/3739b9b6bfe5166c62fcf9e1cf467d89/gr1.sml gr1 gr1.sml sml 5232 163 92 IMAGE-THUMBNAIL 1-s2.0-S0950705118302107-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr2/THUMBNAIL/image/gif/124d2d2fa9e71e7c8d553623cb68a7bd/gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr2/THUMBNAIL/image/gif/124d2d2fa9e71e7c8d553623cb68a7bd/gr2.sml gr2 gr2.sml sml 13906 135 219 IMAGE-THUMBNAIL 1-s2.0-S0950705118302107-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr3/THUMBNAIL/image/gif/a11ca2e04422c969bb94c7151a3eab7b/gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr3/THUMBNAIL/image/gif/a11ca2e04422c969bb94c7151a3eab7b/gr3.sml gr3 gr3.sml sml 9010 97 219 IMAGE-THUMBNAIL 1-s2.0-S0950705118302107-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr4/THUMBNAIL/image/gif/fdc5ecf637f315d7a66ba9d3cf1f319c/gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr4/THUMBNAIL/image/gif/fdc5ecf637f315d7a66ba9d3cf1f319c/gr4.sml gr4 gr4.sml sml 6094 163 76 IMAGE-THUMBNAIL 1-s2.0-S0950705118302107-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr5/THUMBNAIL/image/gif/6c3456f06a5bfe47861b2f7eb9c30b50/gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr5/THUMBNAIL/image/gif/6c3456f06a5bfe47861b2f7eb9c30b50/gr5.sml gr5 gr5.sml sml 14611 149 219 IMAGE-THUMBNAIL 1-s2.0-S0950705118302107-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr6/THUMBNAIL/image/gif/6b1f33a842f2728aa61827eb81301663/gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr6/THUMBNAIL/image/gif/6b1f33a842f2728aa61827eb81301663/gr6.sml gr6 gr6.sml sml 7758 114 219 IMAGE-THUMBNAIL 1-s2.0-S0950705118302107-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr7/THUMBNAIL/image/gif/4f4a91add95dc8763f8af68c0489a1b4/gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr7/THUMBNAIL/image/gif/4f4a91add95dc8763f8af68c0489a1b4/gr7.sml gr7 gr7.sml sml 7592 113 219 IMAGE-THUMBNAIL 1-s2.0-S0950705118302107-gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr8/THUMBNAIL/image/gif/9a7ff8769ea8175abf3cbc53885e5fa1/gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr8/THUMBNAIL/image/gif/9a7ff8769ea8175abf3cbc53885e5fa1/gr8.sml gr8 gr8.sml sml 7625 115 219 IMAGE-THUMBNAIL 1-s2.0-S0950705118302107-gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr9/THUMBNAIL/image/gif/f15275b9c555a91457f89dd40e4b3c7a/gr9.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr9/THUMBNAIL/image/gif/f15275b9c555a91457f89dd40e4b3c7a/gr9.sml gr9 gr9.sml sml 9219 108 219 IMAGE-THUMBNAIL 1-s2.0-S0950705118302107-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr1/DOWNSAMPLED/image/jpeg/1edc382081aa938bea16d21aa6cb22d2/gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr1/DOWNSAMPLED/image/jpeg/1edc382081aa938bea16d21aa6cb22d2/gr1.jpg gr1 gr1.jpg jpg 32881 570 321 IMAGE-DOWNSAMPLED 1-s2.0-S0950705118302107-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr2/DOWNSAMPLED/image/jpeg/1dc18b9b3b7b7e2c303269ac1b78fdc0/gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr2/DOWNSAMPLED/image/jpeg/1dc18b9b3b7b7e2c303269ac1b78fdc0/gr2.jpg gr2 gr2.jpg jpg 108962 497 807 IMAGE-DOWNSAMPLED 1-s2.0-S0950705118302107-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr3/DOWNSAMPLED/image/jpeg/5bb8a92243737e73cf55443cb0777431/gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr3/DOWNSAMPLED/image/jpeg/5bb8a92243737e73cf55443cb0777431/gr3.jpg gr3 gr3.jpg jpg 51913 360 810 IMAGE-DOWNSAMPLED 1-s2.0-S0950705118302107-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr4/DOWNSAMPLED/image/jpeg/aaef088bd348eeb11c3c2f6b3c167d5b/gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr4/DOWNSAMPLED/image/jpeg/aaef088bd348eeb11c3c2f6b3c167d5b/gr4.jpg gr4 gr4.jpg jpg 15374 307 143 IMAGE-DOWNSAMPLED 1-s2.0-S0950705118302107-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr5/DOWNSAMPLED/image/jpeg/f629460f7dd079ed760906e1ba1788ce/gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr5/DOWNSAMPLED/image/jpeg/f629460f7dd079ed760906e1ba1788ce/gr5.jpg gr5 gr5.jpg jpg 144871 549 809 IMAGE-DOWNSAMPLED 1-s2.0-S0950705118302107-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr6/DOWNSAMPLED/image/jpeg/1ee12066014cc368b918670a4f0f9b6d/gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr6/DOWNSAMPLED/image/jpeg/1ee12066014cc368b918670a4f0f9b6d/gr6.jpg gr6 gr6.jpg jpg 42260 353 678 IMAGE-DOWNSAMPLED 1-s2.0-S0950705118302107-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr7/DOWNSAMPLED/image/jpeg/63cc7304a560ed633b5d9e7e5c33e128/gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr7/DOWNSAMPLED/image/jpeg/63cc7304a560ed633b5d9e7e5c33e128/gr7.jpg gr7 gr7.jpg jpg 42821 351 678 IMAGE-DOWNSAMPLED 1-s2.0-S0950705118302107-gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr8/DOWNSAMPLED/image/jpeg/5a1bb086ffe92f44efee044624aaa62c/gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr8/DOWNSAMPLED/image/jpeg/5a1bb086ffe92f44efee044624aaa62c/gr8.jpg gr8 gr8.jpg jpg 43069 355 678 IMAGE-DOWNSAMPLED 1-s2.0-S0950705118302107-gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr9/DOWNSAMPLED/image/jpeg/a12fb1bef71b3298734cede063fd06ac/gr9.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr9/DOWNSAMPLED/image/jpeg/a12fb1bef71b3298734cede063fd06ac/gr9.jpg gr9 gr9.jpg jpg 65067 314 637 IMAGE-DOWNSAMPLED 1-s2.0-S0950705118302107-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr1/HIGHRES/image/jpeg/995961bc54af8be4e9543dc0ee4ad2c9/gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr1/HIGHRES/image/jpeg/995961bc54af8be4e9543dc0ee4ad2c9/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 298310 3033 1707 IMAGE-HIGH-RES 1-s2.0-S0950705118302107-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr2/HIGHRES/image/jpeg/7c7fbd65453bd67072ee227d39ba8848/gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr2/HIGHRES/image/jpeg/7c7fbd65453bd67072ee227d39ba8848/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 1402777 2637 4286 IMAGE-HIGH-RES 1-s2.0-S0950705118302107-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr3/HIGHRES/image/jpeg/bf68d8116fef79d59d7811395653951a/gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr3/HIGHRES/image/jpeg/bf68d8116fef79d59d7811395653951a/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 464809 1911 4302 IMAGE-HIGH-RES 1-s2.0-S0950705118302107-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr4/HIGHRES/image/jpeg/60d28180afe95545ab1b503a231063a0/gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr4/HIGHRES/image/jpeg/60d28180afe95545ab1b503a231063a0/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 124772 1634 760 IMAGE-HIGH-RES 1-s2.0-S0950705118302107-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr5/HIGHRES/image/jpeg/af763d53da82a9398745351968be9db9/gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr5/HIGHRES/image/jpeg/af763d53da82a9398745351968be9db9/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 976341 2431 3583 IMAGE-HIGH-RES 1-s2.0-S0950705118302107-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr6/HIGHRES/image/jpeg/3e7afada4b7c6b28762e69b3645ed496/gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr6/HIGHRES/image/jpeg/3e7afada4b7c6b28762e69b3645ed496/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 282602 1561 3000 IMAGE-HIGH-RES 1-s2.0-S0950705118302107-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr7/HIGHRES/image/jpeg/efd231864b933353c5636ae9a1f04421/gr7_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr7/HIGHRES/image/jpeg/efd231864b933353c5636ae9a1f04421/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 274632 1552 3000 IMAGE-HIGH-RES 1-s2.0-S0950705118302107-gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr8/HIGHRES/image/jpeg/b238dfbb4e73dd558f413cc12d64c9f7/gr8_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr8/HIGHRES/image/jpeg/b238dfbb4e73dd558f413cc12d64c9f7/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 284035 1570 3000 IMAGE-HIGH-RES 1-s2.0-S0950705118302107-gr9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/gr9/HIGHRES/image/jpeg/4076e1ad28a03265c7dcc0a124144453/gr9_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/gr9/HIGHRES/image/jpeg/4076e1ad28a03265c7dcc0a124144453/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 458932 1672 3387 IMAGE-HIGH-RES 1-s2.0-S0950705118302107-mmc1.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/mmc1/MAIN/application/pdf/0622ea2b32b7254ec3d27e9322d7f79d/mmc1.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/mmc1/MAIN/application/pdf/0622ea2b32b7254ec3d27e9322d7f79d/mmc1.pdf mmc1 mmc1.pdf pdf false 60555 APPLICATION 1-s2.0-S0950705118302107-si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/f5784a6d1a2477cd763287eb7aab03a1/si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/f5784a6d1a2477cd763287eb7aab03a1/si1.gif si1 si1.gif gif 386 16 89 ALTIMG 1-s2.0-S0950705118302107-si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/b7f66c94e3433553825af94ef6e60791/si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/b7f66c94e3433553825af94ef6e60791/si10.gif si10 si10.gif gif 624 17 147 ALTIMG 1-s2.0-S0950705118302107-si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/067d93bea3b932e37b9e15863f58f169/si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/067d93bea3b932e37b9e15863f58f169/si11.gif si11 si11.gif gif 2091 45 415 ALTIMG 1-s2.0-S0950705118302107-si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/0f9dc328a7c24f7cb36241f47963e7ec/si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/0f9dc328a7c24f7cb36241f47963e7ec/si12.gif si12 si12.gif gif 517 14 162 ALTIMG 1-s2.0-S0950705118302107-si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/87408df04cdb96254ff73fefdc6a23d2/si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/87408df04cdb96254ff73fefdc6a23d2/si13.gif si13 si13.gif gif 239 14 51 ALTIMG 1-s2.0-S0950705118302107-si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/8b9c436947ec56ef30a7e20ec108dd0d/si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/8b9c436947ec56ef30a7e20ec108dd0d/si14.gif si14 si14.gif gif 260 15 50 ALTIMG 1-s2.0-S0950705118302107-si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/a4783e662e11d5f71f7fa0789d2faa55/si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/a4783e662e11d5f71f7fa0789d2faa55/si15.gif si15 si15.gif gif 1383 45 241 ALTIMG 1-s2.0-S0950705118302107-si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/3efcf976b984a4b4ad8f360195055eb9/si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/3efcf976b984a4b4ad8f360195055eb9/si16.gif si16 si16.gif gif 1471 44 228 ALTIMG 1-s2.0-S0950705118302107-si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/8e51a1ee9fd26c19e41b2089005cef1f/si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/8e51a1ee9fd26c19e41b2089005cef1f/si17.gif si17 si17.gif gif 5165 97 630 ALTIMG 1-s2.0-S0950705118302107-si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/64386fc0b7ae285a4de285ff69913fad/si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/64386fc0b7ae285a4de285ff69913fad/si18.gif si18 si18.gif gif 2513 44 521 ALTIMG 1-s2.0-S0950705118302107-si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/3d21684ac983b4d83c88ae850a7301e9/si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/3d21684ac983b4d83c88ae850a7301e9/si19.gif si19 si19.gif gif 367 15 98 ALTIMG 1-s2.0-S0950705118302107-si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/86471c8cc9045744435c309a494f89e7/si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/86471c8cc9045744435c309a494f89e7/si2.gif si2 si2.gif gif 401 16 101 ALTIMG 1-s2.0-S0950705118302107-si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/1b7738b836e41f5262fed3bd7fcba3b8/si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/1b7738b836e41f5262fed3bd7fcba3b8/si20.gif si20 si20.gif gif 395 15 96 ALTIMG 1-s2.0-S0950705118302107-si21.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/b2cdb3590e8f3f4eb0cc296ae92d3bfd/si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/b2cdb3590e8f3f4eb0cc296ae92d3bfd/si21.gif si21 si21.gif gif 168 24 12 ALTIMG 1-s2.0-S0950705118302107-si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/7435c57d1e3182da4bf4a3d7bf468f06/si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/7435c57d1e3182da4bf4a3d7bf468f06/si22.gif si22 si22.gif gif 426 24 71 ALTIMG 1-s2.0-S0950705118302107-si23.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/be60f7b485a58309012670ba6b7fae93/si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/be60f7b485a58309012670ba6b7fae93/si23.gif si23 si23.gif gif 565 16 141 ALTIMG 1-s2.0-S0950705118302107-si24.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/1844c116046b36ea282a9931c225b3ec/si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/1844c116046b36ea282a9931c225b3ec/si24.gif si24 si24.gif gif 588 17 167 ALTIMG 1-s2.0-S0950705118302107-si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/6717de59847f3bb439447ea6d31c33ae/si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/6717de59847f3bb439447ea6d31c33ae/si25.gif si25 si25.gif gif 268 24 34 ALTIMG 1-s2.0-S0950705118302107-si26.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/a3f47502754fdd893144f6cd14b0d14e/si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/a3f47502754fdd893144f6cd14b0d14e/si26.gif si26 si26.gif gif 1175 25 277 ALTIMG 1-s2.0-S0950705118302107-si27.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/9591ef5597223bf7035d7273e5b61bec/si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/9591ef5597223bf7035d7273e5b61bec/si27.gif si27 si27.gif gif 350 24 45 ALTIMG 1-s2.0-S0950705118302107-si28.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/b710d2238085f53fc2fc92552c5c52a2/si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/b710d2238085f53fc2fc92552c5c52a2/si28.gif si28 si28.gif gif 166 16 35 ALTIMG 1-s2.0-S0950705118302107-si29.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/ba7fbd3b1bb40327f07dce55c99c709d/si29.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/ba7fbd3b1bb40327f07dce55c99c709d/si29.gif si29 si29.gif gif 178 16 35 ALTIMG 1-s2.0-S0950705118302107-si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/2a654a488917088f2c11e09b49658079/si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/2a654a488917088f2c11e09b49658079/si3.gif si3 si3.gif gif 419 16 101 ALTIMG 1-s2.0-S0950705118302107-si30.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/25ee2d9f3a9bc8b31f6e9cd199672e57/si30.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/25ee2d9f3a9bc8b31f6e9cd199672e57/si30.gif si30 si30.gif gif 944 20 241 ALTIMG 1-s2.0-S0950705118302107-si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/db929d9696410ec7135639e60ff73eca/si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/db929d9696410ec7135639e60ff73eca/si31.gif si31 si31.gif gif 990 20 242 ALTIMG 1-s2.0-S0950705118302107-si32.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/67b623e1dbe1fbe381c347fc707de2ac/si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/67b623e1dbe1fbe381c347fc707de2ac/si32.gif si32 si32.gif gif 526 17 171 ALTIMG 1-s2.0-S0950705118302107-si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/e61339674d7d0b228100d78b72efae9e/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/e61339674d7d0b228100d78b72efae9e/si33.gif si33 si33.gif gif 263 13 54 ALTIMG 1-s2.0-S0950705118302107-si34.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/7de3d71a4eaac18277dd06074cfa3e47/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/7de3d71a4eaac18277dd06074cfa3e47/si34.gif si34 si34.gif gif 141 16 12 ALTIMG 1-s2.0-S0950705118302107-si35.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/131091cf11ffed323f14d4406611708a/si35.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/131091cf11ffed323f14d4406611708a/si35.gif si35 si35.gif gif 252 16 56 ALTIMG 1-s2.0-S0950705118302107-si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/1850a20dfcaaa3a121c707828a40ec32/si36.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/1850a20dfcaaa3a121c707828a40ec32/si36.gif si36 si36.gif gif 258 16 57 ALTIMG 1-s2.0-S0950705118302107-si37.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/b58099ed7adfddb4f928ad6d88db14bc/si37.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/b58099ed7adfddb4f928ad6d88db14bc/si37.gif si37 si37.gif gif 224 13 49 ALTIMG 1-s2.0-S0950705118302107-si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/87401b18f8ef95a29ca2ae913bb088ac/si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/87401b18f8ef95a29ca2ae913bb088ac/si38.gif si38 si38.gif gif 215 16 49 ALTIMG 1-s2.0-S0950705118302107-si39.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/b6760134951edbbcaef5fe6d94ac6388/si39.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/b6760134951edbbcaef5fe6d94ac6388/si39.gif si39 si39.gif gif 406 17 84 ALTIMG 1-s2.0-S0950705118302107-si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/ce5906ea6b900c91708e2bdab7da45e1/si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/ce5906ea6b900c91708e2bdab7da45e1/si4.gif si4 si4.gif gif 431 16 117 ALTIMG 1-s2.0-S0950705118302107-si40.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/3c2ab300fdf09a40732d3fce420cf7f4/si40.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/3c2ab300fdf09a40732d3fce420cf7f4/si40.gif si40 si40.gif gif 287 17 102 ALTIMG 1-s2.0-S0950705118302107-si41.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/c07e0a867c68b6cadeedea276f4a3bd0/si41.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/c07e0a867c68b6cadeedea276f4a3bd0/si41.gif si41 si41.gif gif 3076 95 409 ALTIMG 1-s2.0-S0950705118302107-si42.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/cd57feab96827c7a4fe09c807079716e/si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/cd57feab96827c7a4fe09c807079716e/si42.gif si42 si42.gif gif 594 19 163 ALTIMG 1-s2.0-S0950705118302107-si43.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/3d4d88b6a090965b35393004c45c2371/si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/3d4d88b6a090965b35393004c45c2371/si43.gif si43 si43.gif gif 621 19 169 ALTIMG 1-s2.0-S0950705118302107-si44.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/edbfc161d271e12ee2c507b2e28c17b3/si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/edbfc161d271e12ee2c507b2e28c17b3/si44.gif si44 si44.gif gif 794 18 183 ALTIMG 1-s2.0-S0950705118302107-si45.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/59051c1f2957c892bf7eea844118f18d/si45.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/59051c1f2957c892bf7eea844118f18d/si45.gif si45 si45.gif gif 660 16 139 ALTIMG 1-s2.0-S0950705118302107-si46.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/3edcf45cdd11c4e0f32c9879ad933957/si46.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/3edcf45cdd11c4e0f32c9879ad933957/si46.gif si46 si46.gif gif 554 16 117 ALTIMG 1-s2.0-S0950705118302107-si47.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/b3f8ac1fbcf8f956adac8647438007b6/si47.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/b3f8ac1fbcf8f956adac8647438007b6/si47.gif si47 si47.gif gif 654 16 140 ALTIMG 1-s2.0-S0950705118302107-si48.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/5ddd8a38fc4dad4f0d6fbdfcd52feb62/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/5ddd8a38fc4dad4f0d6fbdfcd52feb62/si48.gif si48 si48.gif gif 1656 16 470 ALTIMG 1-s2.0-S0950705118302107-si49.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/d9fc8242b1f783702aae71a0017ab2f5/si49.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/d9fc8242b1f783702aae71a0017ab2f5/si49.gif si49 si49.gif gif 1271 53 217 ALTIMG 1-s2.0-S0950705118302107-si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/2071c5d38d01c67e22ea0d95bab9dbd5/si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/2071c5d38d01c67e22ea0d95bab9dbd5/si5.gif si5 si5.gif gif 526 14 161 ALTIMG 1-s2.0-S0950705118302107-si50.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/e8c9081b41ade6f3c7b2fe2aedc1a693/si50.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/e8c9081b41ade6f3c7b2fe2aedc1a693/si50.gif si50 si50.gif gif 1523 55 245 ALTIMG 1-s2.0-S0950705118302107-si51.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/1694de1113dd22a34e60cfb8ba4ce397/si51.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/1694de1113dd22a34e60cfb8ba4ce397/si51.gif si51 si51.gif gif 1295 55 235 ALTIMG 1-s2.0-S0950705118302107-si52.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/e0f78858cdcaf5b9965aceb31bedfeb0/si52.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/e0f78858cdcaf5b9965aceb31bedfeb0/si52.gif si52 si52.gif gif 1315 55 236 ALTIMG 1-s2.0-S0950705118302107-si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/d95033d03e1672783696cf87075161c5/si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/d95033d03e1672783696cf87075161c5/si6.gif si6 si6.gif gif 349 17 74 ALTIMG 1-s2.0-S0950705118302107-si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/47b0beaafadac08528584d0c78cfd991/si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/47b0beaafadac08528584d0c78cfd991/si7.gif si7 si7.gif gif 368 17 82 ALTIMG 1-s2.0-S0950705118302107-si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/3f179a44c79f042afa265d4376700891/si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/3f179a44c79f042afa265d4376700891/si8.gif si8 si8.gif gif 379 17 85 ALTIMG 1-s2.0-S0950705118302107-si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705118302107/STRIPIN/image/gif/01e077086050fb611697a6df1aac5936/si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0950705118302107/STRIPIN/image/gif/01e077086050fb611697a6df1aac5936/si9.gif si9 si9.gif gif 700 42 129 ALTIMG KNOSYS 4320 S0950-7051(18)30210-7 10.1016/j.knosys.2018.05.001 The Authors Fig. 1 Flowchart of feature selection and vector generation. Fig. 1 Fig. 2 Flowchart of the crawlers. Fig. 2 Fig. 3 Inverted index construction. Fig. 3 Fig. 4 Flowchart of document preprocessing. Fig. 4 Fig. 5 Results of three classes recommendations. Fig. 5 Fig. 6 Accuracy with different number of features for each category using MI. Fig. 6 Fig. 7 Accuracy with different number of features for each category using IG. Fig. 7 Fig. 8 Accuracy with different number of features for each category using Chi-square. Fig. 8 Fig. 9 Macro-averaged ROC of three feature selection models. Fig. 9 Table 1 Two-way contingency table for χ 2 . Table 1 A = # ( t , c ) C = # ( ¬ t , c ) B = # ( t , ¬ c ) D = # ( ¬ t , ¬ c ) N = A + B + C + D Table 2 Accuracy and F-measure of three feature selection models. Table 2 Metrics models MI IG CHI MI IG CHI (Top1) (Top3) Accuracy(%) 20.55 34.06 35.03 41.03 60.51 61.37 F-measure 0.13 0.16 0.18 0.18 0.21 0.23 A content-based recommender system for computer science publications Donghui Wang a xiaozhen1124@sina.com Yanchun Liang a b c ycliang@jlu.edu.cn Dong Xu a c xudong@missouri.edu Xiaoyue Feng a fengxy@jlu.edu.cn Renchu Guan ⁎ a b guanrenchu@jlu.edu.cn a Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun 130012, China Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology Jilin University Changchun 130012 China b Zhuhai Laboratory of Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Zhuhai College of Jilin University, Zhuhai 519041, China Zhuhai Laboratory of Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education Zhuhai College of Jilin University Zhuhai 519041 China c Department of Computer Science, Informatics Institute, and Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO 65211, USA Department of Computer Science, Informatics Institute, and Christopher S. Bond Life Sciences Center University of Missouri Columbia MO 65211 USA ⁎ Corresponding author at: Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology, Jilin University, Changchun 130012, China. Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, College of Computer Science and Technology Jilin University Changchun 130012 China Abstract As computer science and information technology are making broad and deep impacts on our daily lives, more and more papers are being submitted to computer science journals and conferences. To help authors decide where they should submit their manuscripts, we present the Content-based Journals & Conferences Recommender System on computer science, as well as its web service at http://www.keaml.cn/prs/. This system recommends suitable journals or conferences with a priority order based on the abstract of a manuscript. To follow the fast development of computer science and technology, a web crawler is employed to continuously update the training set and the learning model. To achieve interactive online response, we propose an efficient hybrid model based on chi-square feature selection and softmax regression. Our test results show that, the system can achieve an accuracy of 61.37% and suggest the best journals or conferences in about 5 s on average. Keywords Recommender system Softmax regression Chi-square feature selection Computer science publications 1 Introduction With the flourishing of e-commerce, recommender system (RS) is undergoing rapid transformation in almost all aspects. These systems have been applied to many areas, such as movie recommendations [1–3], music recommendations [4,5], news recommendations [6,7], webpage and document recommendations [8]. Many companies have employed and benefited from recommender systems, such as the book recommendation of Amazon, music recommendation of Apple Music, and product recommendation of TaoBao. While recommender systems for many areas have been in various stages of development, to the best our knowledge, a customized recommender system using abstract for authors of computer science publications has not been proposed until now. Meanwhile, with the fast development of artificial intelligence and cloud computing, more and more computer science conferences and journals are available. The number of computer science conferences exceeds 9585 (http://dblp.uni-trier.de/db/conf/) and the number of journals is more than 4152 (http://dblp.uni-trier.de/db/journals/). Facing so many publication venues, it is often hard for authors to select the most suitable journal or conference to publish their papers. Submitting a paper to a wrong journal often causes rejection, delay or less readership of the publication. To help the authors find the most suitable venue and accelerate the submission process, we propose a recommender system on computer science publications referred to as the Publication Recommender System (PRS). This system is based on a new content-based filtering (CBF) recommendation model using chi-square and softmax regression, which are combined to construct a real-time online system. The contributions of the proposed recommendation system are as follows: (1) PRS is a non-profit driven recommender system covering 66 top computer science publication venues across more than five digital libraries, such as Springer, IEEE, ACM, AAAI and SIAM. It can simultaneously recommend top journals and conferences using the input of abstract or the whole manuscript. (2) Considering the continually expanding field of computer science and daily updated corpus of the ever-changing, the recommendation ability for cutting edge research areas and topics is essential. Our recommender model can automatically update once a new training set is formed. It can ensure that those cutting edge research topics can be recommended effectively. (3) PRS could respond to user in real time and easily be deployed on a web server. In order to make PRS more practical, all methods used in PRS are designed to be less computational complexity. The rest of this paper is organized as follows. In Section 2, development process of recommender system and ways to implement recommender system are introduced. In Section 3, we briefly introduce the feature selection and classification methods related to our work, and the methods to select features and classify features used in the publication recommender system are proposed. Experimental results and analysis are in Section 4. The conclusion and future work are in the last section. 2 Background In the late 20th century, Armstrong et al. [9] proposed a personalized navigation system called “Web Watcher” at the AAAI (American Association for Artificial Intelligence). Meanwhile, Balabanovic proposed a personalized recommender system called “LIRA” [10]. In August 1995, Henry Lieberman, from the Massachusetts Institute of Technology, presented a personalized navigation agent “Letizia” at the International Joint Conference on Artificial Intelligence (IJCAI). In 1997, AT&T Labs presented personalized recommendation systems based on collaborative filtering, called “PHOAKS” [11] and “Referral Web” [12]. In 1999, Tanja Joerding of Dresden University of Technology in Germany implemented a personalized e-commerce prototype system, “TELLIM” [13]. In 2001, IBM added personalized features to its e-commerce platform, “Websphere” [14], to enable businesses to develop personalized e-commerce sites. In 2003, Google made “AdWords” profitable which provided relevant ads through keywords that users searched for. In 2009, Overstock (US famous online retailers) began to use ChoiceStream company’s personalized banner advertising program, to run product ads in some high-traffic sites. Most of these recommendations are mainly implemented in two ways: collaborative or content-based filtering [15]. Collaborative filtering approaches learn a model from a user’s past behavior as well as similar decisions made by other users, and predict items (or ratings for items) that users may be interested in [16]. Content-based filtering approaches utilize a series of discrete characteristics of an item in order to recommend additional items with similar properties [17]. The two approaches can also be combined as hybrid recommender systems. Other novel techniques can be introduced into recommendation system, such as social network and semantic information[18,19]. In terms of content-based filtering approaches, it tries to recommend items to the active user similar to those rated positively in the past. It is based on the concept that items with similar attributes will be rated similarly. The information source that content-based filtering systems are mostly used are text documents. A set of descriptors or terms, typically Term Frequency (TF) and Inverse Document Frequency (IDF), are used to describe the items. A standard approach for term parsing selects single words from documents. The vector space model and latent semantic indexing are two methods that use these terms to represent documents as vectors in a multi-dimensional space. CBF is becoming especially important as RS incorporate information on items from users working in web 2.0 environments, such as tags, posts, opinions and multimedia material [20]. 3 Publication recommender system Publication Recommender System consists of two modules: feature selection module and softmax regression module. Feature vector space is generated in feature selection module and feature vectors are used to train softmax regressor in softmax regression module. In this section, details of the two module will be introduced. 3.1 Feature selection module In this subsection, the brief descriptions of TF-IDF and three feature selection models are introduced. Then, the feature selection method for Publication Recommender System is proposed. 3.1.1 TF-IDF Term frequency and inverse document frequency (TF-IDF) can recognize the important words or phrases of articles [21]. It is the most common weighting method used to describe documents in the vector space model [22,23]. If a word is infrequent but its number of occurrence is large in one or a few articles, it probably plays a key role in the article. Moreover, the higher a word’s t f − i d f is, the more important it is in the article. t f − i d f is calculated as a combination of the term frequency and inverse document frequency. tf is the number of times that a word w occurs in the document d. Considering the length of documents, tf should be standardized. (1) t f = T / L . or (2) t f = T / T i . where, T is the term frequency, L is the count of the unique words in document d, and T i denotes the frequency of the most frequent word in document d. idf reveals how much information the word provides. It is calculated using D and D i , where D denotes the number of all documents and D i is the number of the documents which include the word w. (3) i d f = l o g D D i + 1 Then, (4) t f - i d f = t f × i d f . It can be seen that t f − i d f is proportional to T and inversely proportional to D i . 3.1.2 Chi-square feature selection The chi-square statistic (χ 2) measures the dependence between the term t and a category c (such as, in our case, computer journals or conferences), which can be seen as the χ 2 distributions with one degree of freedom to judge extremeness [24]. With a term t and a category c, χ 2 can be achieved using a two-way contingency table [25] (Table 1 ). A is the number of documents including term t, which belongs to category c; B is the number of documents including t, which does not belong to c; C is the number of documents in category c, which does not include t; D is the number of documents in other categories and without term t. The χ 2 of t is defined as: (5) χ 2 ( t , c ) = N × ( A D − B C ) 2 ( A + C ) × ( B + D ) × ( A + B ) × ( C + D ) where N is the total number of documents. Obviously, A + B + C + D = N . A + C and B + D are equal to a constant for each term t in category c when computing χ 2(t, c), and then Eq. (5) can be simplified as: (6) χ 2 ( t , c ) ≈ ( A D − B C ) 2 ( A + B ) × ( C + D ) χ 2 has a natural value of zero if term t and category c are independent, which means term t does not contain any information about category c. In contrast, χ 2 has a high value if term t and category c are dependent. Two other widely used feature selection models—mutual information (MI) and information gain (IG) can be calculated as follows: (7) M I ( t , c ) = l o g ( A / ( A + C ) ( A + B ) / N ) (8) I G ( t , c ) = E n t r o p y ( S ) + A + B N 1 + N 2 ( A A + B l o g ( A A + B ) + B A + B l o g ( B A + B ) ) + C + D N 1 + N 2 ( C C + D l o g ( C C + D ) + D C + D l o g ( D C + D ) ) (9) E n t r o p y ( S ) = − N 1 N 1 + N 2 l o g ( N 1 N 1 + N 2 ) − N 2 N 1 + N 2 l o g ( N 2 N 1 + N 2 ) where N 1 = A + C , N 2 = B + D . All the three metrics are used in our experiments to evaluate the performance of recommendation results in Section 3. 3.1.3 Proposed method The feature selection procedure is to evaluate each feature according to a selection metric and pick the rich informative features. The evaluation involves counting the occurrences of a feature in a class with both positive and negative training examples. As mentioned in the previous subsection, χ 2 is used to measure the lack of independence between the feature t and category c. In fact, what we are interested in are those terms having strong relationships with their category. Therefore, a number of highly dependent words from every text category using χ 2 will be selected to generate a feature vector using Eq. (6). Specifically, suppose Nc is the number of categories in the training set and t j i is the jth unique term in the ith category. The detailed procedure is as follows. Firstly, text preprocessing like tokenization, stop-words removal and stemming are performed on each document. Secondly, we use Eq. (6) to compute χ 2 ( t j i , c i ) for the jth unique term belonging to the ith category. To reconstruct an effective vector space, we sort all χ 2 ( t j i , c i ) in descending order and select the top M terms as the feature vector space FVi of the ith category. At last, we combine all feature vectors F V 1 F V 2 ⋯ F V N c together and remove the duplicate terms to generate a new feature vector space. F V : [ t 1 , t 2 , ⋯ , t N F V ] where NFV is the number of elements in the final feature vector space. For a document j belonging to category i, we define its feature vector F V j i as: (10) F V j i = [ f j i ( t 1 ) , f j i ( t 2 ) , ⋯ , f j i ( t N F V ) ] where f j i ( t k ) is t f − i d f of the kth feature term tk in document j, which belongs to category i. Fig. 1 shows the feature selection and vector generation method. For example, suppose there are two classes of all documents in training set, which are named c 1 and c 2. After text preprocessing, all unique items from c 1 and c 2 are t 1 = {“despit”, “signific”, “invest”, “commerci”} and t 2 = {“far”, “solv”, “week”, “invest”} respectively. Then, we use Eq. (6) to compute χ 2 ( t j i , c i ) which are χ 2 ( t 1 , c 1 ) = { 0.1 , 0.5 , 0.7 , 0.4 } and χ 2 ( t 2 , c 2 ) = { 0.1 , 0.3 , 0.2 , 0.8 } for i = 1 , 2 , j = 1 , 2 , 3 , 4 . We select the top M = 2 terms from t i according to the value of χ 2 as the feature vector space of the ith category, which are F V 1 = {“signific”, “invest”} and F V 2 = {“solv”, “invest”}. Finally, we combine FV 1 and FV 2 together and remove the duplicate terms to generate the feature vector space F V = {“signific”, “invest”, “solv”}. It should be noted that all data above are not real and for simulation only. 3.2 Softmax regression module Since features are selected and the feature vector space is generated, feature vectors could be computed easily and used to train a classifier. Softmax regression is chosen to be the classifier because there are many journals and conferences in the recommender system and all journals and conferences need to be ranked for recommending according to the classification scores. 3.2.1 Softmax regression Softmax regression is the extension of logistic regression, which can solve multi-class problems (the number of classes c > 2). When c = 2 , softmax regression is degenerated to logistic regression. Given a test input x, our hypothesis is to estimate the probability of p ( y = j | x ) for each value of j = 1 , ⋯ , k . Thus, the hypothesis leads to output of a k dimensional vector (whose elements’ sum is 1), giving us k estimated probabilities: (11) h θ ( x ) = [ p ( y = 1 | x ; θ ) p ( y = 2 | x ; θ ) ⋯ p ( y = k | x ; θ ) ] = 1 ∑ j = 1 k e θ j T x [ e θ 1 T x e θ 2 T x ⋯ e θ k T x ] where θ 1 , θ 2 , ⋯ , θ k ∈ R n + 1 are parameters of the model. Because it is of low computational complexity and easy to perform, we selected softmax regression to predict recommendation results. 3.2.2 Proposed method Softmax regression module generalizes logistic regression to classification problems where the class label y can take more than two possible values, which means it can be used for multi-class classification problems. After feature selection procedure, a document of training data set is represented using t f − i d f according to the FV. The softmax regression is used as a classifier. When training Softmax, x and y of a sample (x, y) represent the feature vector and category of that sample respectively. Feature vector x is computed using Eq. (10), which is as the input data of Softmax. When testing the trained model, the way to extract the feature vector x of a document is exactly the same as training. The multi-label classification results are used to recommend for that document, which means that the predicted class from model is the recommended category. In specific, we chose the Top 3 classes according to the probability p(y|x) instead of only one from our model’s output as the final classification result. The reason is that the publication scopes of some computer journals and conferences have significant overlaps among them (e.g. International Conference on Computer Vision, IEEE Conference on Computer Vision and Pattern Recognition and IEEE Transactions on Image Processing). Therefore, if a manuscript falls into these publication scopes (such as image classification), its publication choice is often more than one. In addition, it will give the user more choices. 4 Experimental results and analysis 4.1 Dataset In our experiments, the abstracts of computer science papers from different journals and conferences are collected for training. To get the abstracts and other information, a special automatic web crawler is constructed. We manually collected home page links as “root links” of 28 journals and 38 conferences (listed in supplementary material), which were ranked as A-class by the China Computer Federation (CCF) [26]. Fig. 2 describes how the automatic crawler works. Firstly, a root link is taken out from DB_0 which stores “root links”. Then, all links are extracted from page content of the root link using a series of regular expressions. Thirdly, those links whose page content listing papers of specific years (e.g. year 2013–2014) will be kept and each address of papers in the paper list will be inserted into database DB_1. A flag CRAWLED_FLAG of the address will be set as 0 as long as the INSERT operation is successful (implemented by database trigger), which means that the address is a new one. In addition, a paper address is taken out from DB_1. If the address is not crawled before (i.e. its CRAWLED_FLAG=0), useful information (such as abstracts, authors, etc.) in the manuscript will be crawled and stored into DB_2 as a new document for training. After that, its flag CRAWLED_FLAG will be set as 1, which means the address has been crawled. Finally, another root link is going to be taken out from DB_0 and analyzed accordingly. These procedures in the flowchart ensure that the crawler will work automatically and continuously to update the training dataset. The distribution of training and testing dataset is shown in Supplementary Material. There are totally 14,012 records containing title, abstract, author and link of papers. To ensure the records in the dataset are correct, 20 percent of abstracts from each journal and conference are checked manually. Two-thirds of all abstracts are used as training samples, and the rest are used for testing. In experiment, papers published in 2014 and 2013 are considered. Specially, for some journals or conferences which did not publish enough papers between 2013 and 2014, papers published in other years are also considered. To compute t f − i d f for each term, instead of searching documents, we use the inverted index to compute t f − i d f in the feature vector space. Fig. 3 is the inverted index construction figure. 4.2 Text preprocessing Preprocessing not only can reduce the computational complexity but also improve the recommender performance. Moreover, text preprocessing is also necessary before generating the inverted index. Fig. 4 shows the flowchart of preprocessing in our system. The first step of preprocessing is tokenization with white space and punctuation. After that, we use stop-words (listed in Supplementary Material) to filter those meaningless tokens such as auxiliary verbs, prepositions, conjunctions, and interjections. There are also some tokens with the same word root but in different forms, e.g. “create”: “created” and “creating”. Therefore, stemming is also required to degenerate different grammatical forms of a word to its root form [27]. We use the state-of-the-art stemming algorithm, that is, “Porter Stemmer” in our system [28]. 4.3 Experiments and analysis The new proposed system provides two kinds of recommendation results: one-class and three-class. The one-class (Top1) version recommends only one journal or conference, and it is very strict to evaluate the recommendation result. And the three-class (Top3) version shows three candidate journals or conferences for a manuscript (see Fig. 5 ), which shows the result of a query in our recommender system. The three-class (Top3) version is evaluated by selecting the top three categories as recommendation results. In other words, if one of the outputs of recommender system matches the publication journal or conference, it can be considered as a successful recommendation. The three-class version could provide more choices for users. In addition, different conferences or journals often share similar publication scopes, such as ICCV, CVPR, TIP, etc. Furthermore, some journal papers are the extended versions of conference papers. To generate a good feature space, we performed several experiments on selecting the features for each category. Chi-square, MI and IG are implemented to make comparisons for feature selection. The top M terms are selected as the ith category feature vector to construct the FVi . Considering the tradeoff between accuracy and efficiency, M is set as 200 according to experimental results shown in Fig. 8. Then, we combine F V 1 , F V 2 , ⋯ , F V N c and remove duplicated terms. For chi-square statistics, we achieve N F V - C h i - S q u a r e = 11 , 521 feature space dimensions. For MI and IG, we also select the top 200 terms for each category and get N F V - M I = 12 , 696 and N F V - I G = 6101 dimensional feature spaces by combining and merging strategy, respectively. With respect to time complexity in testing phase, it can be calculated as follows. Suppose that Nw is the number of unique words or phases in an abstract, NFV is the number of elements in feature vector and Nc is the number of conferences and journals in the system. In document preprocessing step, time complexity is O(Nw ). Because Inverse Index table has been constructed and stored into database ahead, so the calculation quantity of t f − i d f is constant const. Therefore, in feature vector computing step, time complexity is O(NFV *const). In softmax regression step, time complexity is O ( N F V * N c + N c ) . Overall, the time complexity of predicting an abstract is O ( N w + N F V * c o n s t + N F V * N c + N c ) = O ( N w + N F V * N c ) . Accuracy (Eq. (12)), F-measure (Eq. (13)) from [29] and ROC are used to evaluate the recommender system. Because our system uses multi-label classification model, we use macro-averaged ROC, which are defined in Eqs. (14) and (15). (12) A c c u r a c y = ∑ i = 1 N | P i ⋂ G i | ∑ i = 1 N | G i | (13) F - m e a s u r e = 1 N ∑ i = 1 N 2 | P i ⋂ G i | | P i | + | G i | (14) T P R m a c r o = 1 N ∑ i = 1 N T P i T P i + F N i (15) F P R m a c r o = 1 N ∑ i = 1 N F P i F P i + T N i where Pi is the set of test samples predicted as the ith category and Gi is the set of test samples labeled as the ith category. TPi, FNi, FPi and TNi are the number of true positives, false negatives, false positives and true negatives for ith category respectively. Figs. 6–8 depict the accuracy of training and testing data with a different number of features for each category using MI, IG and chi-square feature selection models, respectively . Fig. 9 and Table 2 show the comparison results of the three feature-selection models. In Fig. 6, it is obviously that the MI based model gets high accuracy on training set and low accuracy on testing set when the number of features is around 60, i.e. model with those features are not generalized enough. The reason is that noise features are selected by MI based model. Those noise features are well applicable for training set but not for testing set. It is the noise features that directly lead to the valley in the curve. When the number of elements in feature vector are larger 150, the model performs better gradually because the features selected by MI become discriminative for both training and testing set. In Fig. 7 and 8, the models perform better with the number of elements in feature vector increasing. The curves of the two models do not show valleys because they do not select the noise features at the beginning. This concludes that features selected by IG and chi-squared are more discriminative than MI. From Figs. 6–8, it can be seen that: 1) Using IG and chi-square selection method, the accuracy increases with the feature number, going up from 30 without decreasing. However, the accuracy of the MI based model has a 16.60% drop from the starting point to 70 features for each class. After the minimum, it climbs up as the feature number increases. But even with 400 features, the MI based model can only reach the accuracy of 55.7%, which is 7.9% and 9.3% less than the IG and chi-square based model, respectively. 2) The classification accuracy of a chi-square based model is always better than MI and IG. For example, at the beginning of testing accuracy curves, the chi-square based model was 78.7% and 1.2% higher than MI and IG, respectively; at the end, it achieves a higher 12.2% and 2.8% accuracy rating than the other two, respectively. From Fig. 9, we can see that: AUCs (Area Under Curve) of chi-squared and IG based models are much higher than MI based model. Chi-square has an AUC of 0.9404, while IG has 0.9415. Both chi-squared and IG have approximately 14.5% higher AUC than MI, which has 0.8273. From the comparison of AUC, it seems that MI is not a good choice for feature selection in publication recommendation. Hence, chi-square and IG are more suitable. From Table 2, we can see that: 1) Results of Top3 are much higher than that of Top1. For example, the accuracy of chi-square based classification accuracy can reach 61.37% for the Top3 task, which is 75.2% higher than Top1. It is because that Top3 can give a higher solution space. In fact, different conferences or journals often share similar publication scopes, and the results of Top1 are strictly programmed to provide only one candidate. 2) The chi-square model achieves the highest accuracies and F-measures. For example, the accuracy of chi-square for Top3 is 61.37%, which is 49.6% higher than MI and 1.4% higher than IG. On F-measure, Chi-Square gets 0.23, which is 27.7% higher than MI and 9.5% higher than IG. This is because the features selected by chi-square for each category are less independent when compared to other categories. IG gets a 47.5% higher accuracy rating than MI and a 16.7% higher accuracy rating on F-measures. Meanwhile, for the strict Top1 tasks, chi-square achieves 35.03% and 0.18 on accuracy and F-measure, which are a 70.5% and 2.8% higher accuracy rating than MI and IG, respectively. It also performs better on F-measure, with a 38.2% and 13.1% higher than MI and IG. From the comparison of the experiment results, it also seems that chi-square and IG are more suitable than MI for feature selection in publication recommendation. 5 Conclusions We developed a content-based journal and conference recommender system for computer science and technology. As far as we know, there is no similar recommender system or published method like what we have introduced here. Moreover, there was no dataset to use. Therefore, we first designed a web crawler to collect data and generate training and testing data sets. Then, we used different feature selection methods and performed several experiments to select a good strategy and reconstruct feature space. Finally, using a softmax regression model, the system shows a three class-recommendation solution to help user find out the candidate journal or conference. In this paper, the proposed recommendation method is used for recommending computer science publications. It is worth mentioning that only abstract of a paper is used to recommend. The method could also be used by other e-library recommender systems[8]. For example, the results of the recommendation could be used to help readers to quickly determine the domain of a paper or to retrieve similar papers. The method could be also used in e-business applications. For example, a business user’s preferences can be summarized as a text (like abstract of a paper) and some recommendations, such as the engaged business area, could be generated using our proposed method based on the text. These recommendations facilitate the decision process of a business user (e.g., buyer) in selecting qualified business partners (e.g., sellers)[18]. Although achieving 61.37% accuracy for paper recommendation, we believe that the accuracy and F-measure can be further improved, which will be our future work. Acknowledgments This study is supported by the National Natural Science Foundation of China (61602207, 61572228, 61472158), the National Basic Research Program of China (2015CB453000), and the Science Technology Development Project from Jilin Province (20160101247JC and 20140520070JH). Premier-Discipline Enhancement Scheme supported by Zhuhai Government and Premier Key-Discipline Enhancement Scheme supported by Guangdong Government Funds. Supplementary material Supplementary material associated with this article can be found, in the online version, at 10.1016/j.knosys.2018.05.001 Appendix A Supplementary materials Supplementary Data S1 Supplementary Raw Research Data. This is open data under the CC BY license http://creativecommons.org/licenses/by/4.0/ Supplementary Data S1 References [1] M.-H. Chen C.-H. Teng P.-C. Chang Applying artificial immune systems to collaborative filtering for movie recommendation Adv. Eng. Inf. 29 4 2015 830 839 [2] Q. Diao M. Qiu C.-Y. Wu A.J. Smola J. Jiang C. Wang Jointly modeling aspects, ratings and sentiments for movie recommendation (JMARS) Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 2014 ACM 193 202 [3] W. Qu K.-S. Song Y.-F. Zhang S. Feng D.-L. Wang G. Yu A novel approach based on multi-view content analysis and semi-supervised enrichment for movie recommendation J. Comput. Sci. Technol. 28 5 2013 776 787 [4] M. Schedl D. Hauger Tailoring music recommendations to users by considering diversity, mainstreaminess, and novelty Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval 2015 ACM 947 950 [5] M. Kaminskas F. Ricci M. Schedl Location-aware music recommendation using auto-tagging and hybrid matching Proceedings of the 7th ACM conference on Recommender systems 2013 ACM 17 24 [6] J. Turcotte C. York J. Irving R.M. Scholl R.J. Pingree News recommendations from social media opinion leaders: effects on media trust and information seeking J. Comput. Mediated Commun. 20 5 2015 520 535 [7] F. Hopfgartner B. Kille A. Lommatzsch T. Plumbaum T. Brodt T. Heintz Benchmarking news recommendations in a living lab International Conference of the Cross-Language Evaluation Forum for European Languages 2014 Springer 250 267 [8] J. Lu D. Wu M. Mao W. Wang G. Zhang Recommender system application developments: a survey Decis. Support Syst. 74 2015 12 32 [9] R. Armstrong D. Freitag T. Joachims T. Mitchell WebWatcher: a learning apprentice for the world wide web AAAI Spring symposium on Information gathering from Heterogeneous, distributed environments 1995 6 12 [10] M. Balabanovic Y. Shoham Learning information retrieval agents: experiments with automated web browsing On-line Working Notes of the AAAI Spring Symposium Series on Information Gathering from Distributed, Heterogeneous Environments 1995 13 18 [11] L. Terveen W. Hill B. Amento D. McDonald J. Creter PHOAKS: a system for sharing recommendations Commun. ACM 40 3 1997 59 62 [12] H. Kautz B. Selman M. Shah Referral web: combining social networks and collaborative filtering Commun. ACM 40 3 1997 63 65 [13] T. Joerding A temporary user modeling approach for adaptive shopping on the web Proceedings of Second Workshop on Adaptive Systems and User Modeling on the World Wide Web, Toronto and Banff, Canada. Computer Science Report 1999 99 107 [14] B. Moore R. Janker B. Papez L. Power R. Watkins Migrating weblogic applications to websphere advanced edition IBM Redbooks 2001 1 [15] H. Jafarkarimi A.T.H. Sim R. Saadatdoost A naive recommendation model for large databases Int. J. Inf. Educ. Technol. 2 3 2012 216 [16] P. Melville V. Sindhwani Recommender systems Encyclopedia of Machine Learning 2011 Springer 829 838 [17] R.J. Mooney L. Roy Content-based book recommending using learning for text categorization Proceedings of the Fifth ACM Conference on Digital Libraries 2000 ACM 195 204 [18] Q. Shambour J. Lu A trust-semantic fusion-based recommendation approach for e-business applications Decis. Support Syst. 54 1 2012 768 780 [19] M. Mao J. Lu G. Zhang J. Zhang Multirelational social recommendations via multigraph ranking IEEE Trans. Cybern. 47 12 2017 4049 4061 [20] J. Bobadilla F. Ortega A. Hernando A. Gutiérrez Recommender systems survey Knowl. Based Syst. 46 2013 109 132 [21] B. Chen H. He J. Guo Constructing maximum entropy language models for movie review subjectivity analysis J. Comput. Sci. Technol. 23 2 2008 231 239 [22] N. Gupta P. Saxena J. Gupta Document summarisation based on sentence ranking using vector space model Int. J. Data Min. Model. Manag. 5 4 2013 380 406 [23] R. Costa C. Lima Document clustering using an ontology-based vector space model Int. J. Inf. Retr. Res. 5 3 2015 39 60 [24] C. Jin T. Ma R. Hou M. Tang Y. Tian A. Al-Dhelaan M. Al-Rodhaan Chi-square statistics feature selection based on term frequency and distribution for text categorization IETE J. Res. 61 4 2015 351 362 [25] A. Moh’d A Mesleh Chi square feature extraction based SVMs arabic language text categorization system J. Comput. Sci. 3 6 2007 430 435 [26] CCF recommended ranking, 2015. [27] M.A. Otair Comparative analysis of arabic stemming algorithms Int. J. Manag. Inf. Technol. 5 2 2013 1 [28] M.F. Porter An algorithm for suffix stripping Program 14 3 1980 130 137 [29] E. Gibaja S. Ventura A tutorial on multilabel learning ACM Comput. Surv. 47 3 2015 52\n"
     ]
    }
   ],
   "source": [
    "show_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
